# Public Release Dataset

This directory contains the subset of the human evaluation data prepared for public sharing.
The data is generated by `human_evaluation_result_analysis/result_analysis.py` when the
analysis pipeline runs.

## Files

- `wide_data_public.csv`: Aggregated evaluation responses with financial decision targets
  and review metadata. The file is regenerated when `result_analysis.py` is executed.

## Columns

- `Clarity`: Likert rating of how clear the generated report is.
- `Freecomment`: Free-form evaluator comment for the report.
- `Logic`: Likert rating of logical soundness.
- `Persuasiveness`: Likert rating of persuasive strength.
- `Readability`: Likert rating of readability.
- `Usefulness`: Likert rating of usefulness for decision making.
- `doc_id`: Identifier for the evaluated document.
- `financial_decision_day`: Next-day trading signal annotated by the evaluator.
- `financial_decision_month`: Next-month trading signal annotated by the evaluator.
- `financial_decision_week`: Next-week trading signal annotated by the evaluator.
- `generated_report`: Text of the generated report reviewed by participants.
- `team_id`: Identifier for the evaluation team.
- `company_id`: Identifier for the underlying company.
- `company_name`: Name of the underlying company.

## Regeneration

1. Ensure the required source CSV files are available in `human_evaluation_result_analysis`.
2. Run `python result_analysis.py` from the repository root.
3. The updated `wide_data_public.csv` will be written to this directory.

## License and Privacy

Review the originating datasets for any privacy or licensing constraints before further
sharing. Remove rows that contain sensitive information not intended for public release.
